{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ad914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages using pip\n",
    "%pip install pypdf langchain_community langchain langchain_openai neo4j_genai langchain_experimental IPython neo4j yfiles_jupyter_graphs yfiles_jupyter_graphs_for_neo4j==1.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf86a7",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "This section initializes the notebook by importing necessary libraries and loading environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "import ast\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Check if running in Google Colab and enable custom widget manager if true\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from 'credentials.env' if it exists\n",
    "if os.path.exists('credentials.env'):\n",
    "    load_dotenv('credentials.env', override=True)\n",
    "\n",
    "    # Neo4j credentials\n",
    "    uri = os.getenv('NEO4J_URI')\n",
    "    username = os.getenv('NEO4J_USERNAME')\n",
    "    password = os.getenv('NEO4J_PASSWORD')\n",
    "    database = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "    # OpenAI credentials\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "else:\n",
    "    print(\"File 'credentials.env' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee901e91",
   "metadata": {},
   "source": [
    "## Create Text Chunks and Generate Embeddings\n",
    "This section splits the PDF document into chunks and generates embeddings for each chunk using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df539ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter with specified chunk size and overlap\n",
    "chunk_size = 800\n",
    "chunk_overlap = 100\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap  = chunk_overlap,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split the PDF document into chunks\n",
    "doc_path = 'microsoft-blogpost.pdf'\n",
    "all_chunks = []\n",
    "\n",
    "loader = PyPDFLoader(doc_path)\n",
    "pages = loader.load_and_split()\n",
    "for page in pages:\n",
    "    chunks = text_splitter.split_text(page.page_content)\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append(chunk)\n",
    "        \n",
    "print(f\"Parsed: {doc_path}\")\n",
    "print(f\"Chunked {len(pages)} pages into {len(all_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first two chunks to ensure correct splitting\n",
    "print('\\nFirst chunk: \\n' + all_chunks[0])\n",
    "print('\\nSecond chunk: \\n' + all_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a83101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each chunk using OpenAI model\n",
    "model = 'text-embedding-3-small'\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model = model,\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")\n",
    "embeddings = []\n",
    "for chunk in all_chunks:\n",
    "    embeddings.append(embeddings_model.embed_query(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f51b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first embedding to ensure correct generation\n",
    "print(all_chunks[0])\n",
    "print('\\nFirst embedding (sample): \\n' + str(embeddings[0][1:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1ce2d",
   "metadata": {},
   "source": [
    "## Write Data to Neo4j\n",
    "This section shows how to clear the existing database, create document nodes, and link text chunks with their embeddings in Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Neo4j and clear the database\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password), database=database)\n",
    "driver.execute_query('MATCH (n) DETACH DELETE n')\n",
    "print(\"Database cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459f30c-c015-49c9-9fab-701e57ca58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_query(\"\"\"\n",
    "CREATE VECTOR INDEX vecindex IF NOT EXISTS\n",
    "FOR (m:Chunk)\n",
    "ON m.embedding\n",
    "OPTIONS {indexConfig: {\n",
    " `vector.dimensions`: 1536,\n",
    " `vector.similarity_function`: 'cosine'\n",
    "}}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document node for the PDF\n",
    "driver.execute_query('CREATE (d:Document{name:\"'+doc_path+'\"})')\n",
    "print('Document created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunk nodes and link them to the document node\n",
    "for index, chunk in enumerate(all_chunks):\n",
    "    embedding = embeddings[index]\n",
    "    driver.execute_query(f\"\"\"\n",
    "    MATCH (d:Document)\n",
    "    WHERE d.name = '{doc_path}'\n",
    "    CREATE (d)-[:HAS_CHUNK]->(c:Chunk)\n",
    "    SET c.text = '{chunk}'\n",
    "    SET c.embedding = {embedding}\n",
    "    SET c.index = {index}\n",
    "    \"\"\")\n",
    "    \n",
    "print('Embeddings set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8cf07",
   "metadata": {},
   "source": [
    "## Visualize the Graph\n",
    "Use yFiles Jupyter graphs for Neo4j to visualize the document and its chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the document and chunks in Neo4j\n",
    "from yfiles_jupyter_graphs_for_neo4j import Neo4jGraphWidget\n",
    "widget = Neo4jGraphWidget(driver, overview_enabled=False, context_start_with=None)\n",
    "widget.show_cypher(\"MATCH (d:Document)-[r]->(c:Chunk) RETURN d,r,c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763a0dc-809d-4c1b-8bbe-5506ab8bbf96",
   "metadata": {},
   "source": [
    "## Extract Graph from Text\n",
    "Use LangChain to extract entities from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cd0ce-8c33-4f07-b8c8-47133b0e3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graph Schema\n",
    "# either one can be set to 'None' to let the model infer data.\n",
    "allowed_nodes = [\"Capability\", \"Service\", \"Organization\", \"Department\", \"Industry\", \"DataSource\", \"Person\", \"Article\"]\n",
    "allowed_relationships = [\"PROVIDED_BY\",\"HAS_SERVICE\",\"ENABLES_CAPABILITY\",\"USED_BY\",\"USES_DATA_FROM\",\"BELONGS_TO_DEPARTMENT\",\"CONNECTS_TO\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcefe4f-5b7d-433e-b23b-a39e97073948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and initialize LangChain's LLMGraphTransformer\n",
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm, \n",
    "    allowed_nodes=allowed_nodes, \n",
    "    allowed_relationships=allowed_relationships)\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize dictionaries to store nodes and relationships\n",
    "nodes = {}\n",
    "rels = {}\n",
    "\n",
    "# Define functions to generate unique hashes for nodes and relationships\n",
    "def get_node_hash(node):\n",
    "    return hash(node.id + ':' + node.type)\n",
    "\n",
    "def get_rel_hash(rel):\n",
    "    return hash(rel.source.id + ':' + rel.source.type + ':' + rel.type + ':' + rel.target.id + ':' + rel.target.type)\n",
    "\n",
    "# Process each text chunk to extract graph information\n",
    "for index, chunk in enumerate(all_chunks):\n",
    "    documents = [Document(page_content=chunk)]\n",
    "    graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "    # Extract unique nodes from the LangChain output\n",
    "    for node in graph_documents[0].nodes:\n",
    "        node_hash = get_node_hash(node)\n",
    "        if node_hash in nodes:\n",
    "            nodes[node_hash]['chunks'].append(index)\n",
    "        else:\n",
    "            nodes[node_hash] = {'id': node_hash, 'name': node.id, 'label': node.type, 'chunks': [index]}\n",
    "\n",
    "    # Extract unique relationships from the LangChain output\n",
    "    for rel in graph_documents[0].relationships:\n",
    "        rel_hash = get_rel_hash(rel)\n",
    "        if rel_hash in rels:\n",
    "            rels[rel_hash]['chunks'].append(index)\n",
    "        else:\n",
    "            source_hash = get_node_hash(rel.source)\n",
    "            target_hash = get_node_hash(rel.target)\n",
    "            rels[rel_hash] = {'id': rel_hash, 'source': source_hash, 'target': target_hash, 'type': rel.type, 'chunks': [index]}\n",
    "\n",
    "    print(f\"Loaded chunk {index+1}/{len(all_chunks)} Current nodes: {len(nodes)}, relationships: {len(rels)}...\")\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e1070-c4fa-4ca0-8330-080f7248f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write nodes to Neo4j and link them to the corresponding chunks\n",
    "## TODO -> this needs some optimization using parameters / batching.\n",
    "for node in nodes.values():\n",
    "    driver.execute_query(f\"\"\"\n",
    "    CREATE (n:{node['label']})\n",
    "    SET n.name = \"{node['name']}\"\n",
    "    SET n.id = \"{node['id']}\"\n",
    "    WITH n\n",
    "    UNWIND {str(node['chunks'])} as chunk_index\n",
    "    MATCH (c:Chunk)\n",
    "    WHERE c.index = chunk_index\n",
    "    CREATE (n)-[:IN]->(c)\n",
    "    \"\"\")\n",
    "\n",
    "print('Nodes created and linked to chunks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027eb24f-3e25-475b-b90e-b53d048ddf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write relationships to Neo4j\n",
    "## TODO -> this needs some optimization using parameters / batching.\n",
    "for rel in rels.values():\n",
    "    driver.execute_query(f\"\"\"\n",
    "    MATCH (n), (m)\n",
    "    WHERE n.id = \"{rel['source']}\" AND m.id = \"{rel['target']}\"\n",
    "    CREATE (n)-[r:{rel['type']}]->(m)\n",
    "    SET r.chunks = {str(rel['chunks'])}\n",
    "    SET r.id = {str(rel['id'])}\n",
    "    \"\"\")\n",
    "\n",
    "print('Relationships created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69dcefa-e79b-4420-a84b-cdae1a1aa677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph in Neo4j\n",
    "from yfiles_jupyter_graphs_for_neo4j import Neo4jGraphWidget\n",
    "widget = Neo4jGraphWidget(driver, overview_enabled=False, context_start_with=None)\n",
    "widget.show_cypher(\"MATCH (d)-[r]->(c) WHERE type(r) <> 'IN' AND type(r) <> 'HAS_CHUNK' RETURN d,r,c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf31c0-b04a-46ee-bc8e-2a04d2c2f444",
   "metadata": {},
   "source": [
    "## Time for Querying\n",
    "We now demonstrate how to use both regular VectorRAG and GraphRAG to ask questions to the database:\n",
    "- The VectorRAG implementation uses only the chunked text and their embeddings.\n",
    "- The GraphRAG implementation also uses the context around the documents (extracted entities and their relationships) to generate an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b85abc-9bd4-4d06-94e8-14ec30c82b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j_genai.retrievers import VectorRetriever, VectorCypherRetriever\n",
    "from neo4j_genai.llm import OpenAILLM\n",
    "from neo4j_genai.generation import GraphRAG\n",
    "from neo4j_genai.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "index_name = \"vecindex\"\n",
    "### Set up the RAG framework\n",
    "\n",
    "# 1. Connect to Neo4j database\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password), database=database)\n",
    "\n",
    "# 2. Create Embedder object, needed to convert the user question (text) to a vector\n",
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 3. LLM\n",
    "llm = OpenAILLM(model_name=\"gpt-4o\", model_params={\"temperature\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefb0d0-2d2b-48df-933d-2775fa35f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector RAG:\n",
    "retriever = VectorRetriever(driver, index_name, embedder)\n",
    "# Initialize the RAG pipeline (note: this is just using plain vector RAG without context)\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# Query the graph\n",
    "query_text = \"Which Microsoft service can Reps on the road use?\"\n",
    "response = rag.search(query_text, retriever_config={\"top_k\": 3})\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a564ca-2839-4b35-9bc3-8afb8192169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, context-aware GraphRAG\n",
    "retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=index_name,\n",
    "    retrieval_query=\"\"\"\n",
    "    // Retrieve Neighbourhood (Context)\n",
    "    MATCH path=(node)<-[r:IN]-(node2)\n",
    "    OPTIONAL MATCH (node2)-[r2]-(node3) \n",
    "    WHERE type(r2) <> \"IN\"\n",
    "    RETURN node.index as chunkindex, node2.id as sourceid, node2.name as source, \n",
    "    toString(r2.id) as relid, type(r2) as reltype, \n",
    "    node3.id as targetid, node3.name as targetname, \n",
    "    score\"\"\",\n",
    "    embedder=embedder\n",
    ")\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# Query the graph\n",
    "response = rag.search(query_text, retriever_config={\"top_k\": 3}, return_context=True)\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651b262-7bbe-4a2d-b2e8-c95be21f3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Define the regex pattern to match key-value pairs\n",
    "pattern = re.compile(r\"(\\w+\\.\\w+|type\\(r2\\)|\\w+)=('[^']*'|\\d+\\.\\d+|\\d+|[^' \\n]+)\")\n",
    "\n",
    "\n",
    "used_context = [item.content for item in response.retriever_result.items]\n",
    "used_context = [re.findall( pattern, item) for item in used_context]\n",
    "used_context = [{key: value.replace(\"'\",\"\") for key, value in matches} for matches in used_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e770c4-e959-45a2-a0eb-e40b04c426d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph in Neo4j\n",
    "from yfiles_jupyter_graphs_for_neo4j import Neo4jGraphWidget\n",
    "widget = Neo4jGraphWidget(driver, overview_enabled=False, context_start_with=None)\n",
    "widget.show_cypher(\"\"\"\n",
    "UNWIND $context as row\n",
    "MATCH (c:Chunk)-[r1]-(n)-[r2]-(m) \n",
    "WHERE c.index = toInteger(row['chunkindex']) AND n.id = row['sourceid'] AND r2.id = toInteger(row['relid']) AND m.id = row['targetid']\n",
    "RETURN c, r1, n, r2, m\n",
    "\n",
    "\"\"\", context=used_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c551218-eae6-48de-a289-7ee0448c9689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780b22b-d502-4aaf-a532-c8b3dd673439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6a0b6-cd5a-4f48-a01c-48cf42c150a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65276dd5-bd7c-4577-ac29-94bd495e8e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ee5ad-b875-4365-b88c-e31de804ad8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c8caf-c6ce-463e-b345-41e7f01d2021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09fa53-97f6-400c-b7bd-361d5544bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
